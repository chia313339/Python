{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20170628 Tensorflow上午實作部分程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read csv\n",
    "def read_dataset(path_to_file):\n",
    "    return genfromtxt(path_to_file, delimiter=delimiter, skip_header=1)\n",
    "\n",
    "def read_boston_data():\n",
    "    data = read_dataset(path_to_file)\n",
    "    features = data[:, :-1]\n",
    "    prices = data[:, -1]\n",
    "    return features, prices\n",
    "\n",
    "# main\n",
    "# path_to_file 放自己檔案位置\n",
    "path_to_file='/Users/chia/Downloads/boston.csv'\n",
    "delimiter=','\n",
    "features, price=read_boston_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Normalization 統計標準化，使變數服從常態分配\n",
    "def feature_normalize(dataset):\n",
    "    mu=np.mean(dataset,axis=0)\n",
    "    sigma=np.std(dataset,axis=0)\n",
    "    return(dataset-mu)/sigma\n",
    "\n",
    "# main\n",
    "normalized_features = feature_normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Constant/Bias 模型偏差\n",
    "def append_bias_reshape(features,price):\n",
    "    n_samples, n_dim = features.shape\n",
    "    expended_features=np.c_[np.ones(n_samples),features]\n",
    "    return expended_features, price.reshape(n_samples,1)\n",
    "\n",
    "# main\n",
    "f,p=append_bias_reshape(normalized_features,price)\n",
    "\n",
    "# 這一段只是在整個資料矩陣最左邊加入全為'1'的欄，維度是(506, 14)，叫做f。\n",
    "# 可以用以下方式觀察\n",
    "# print(f)\n",
    "# print(f[0,])\n",
    "# p則是模型的Ｙ值，維度為(506, 1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "random_indices = np.random.rand(len(f)) < 0.8\n",
    "\n",
    "x_train = f[random_indices]\n",
    "y_train = p[random_indices]\n",
    "x_test = f[~random_indices]\n",
    "y_test = p[~random_indices]\n",
    "\n",
    "# 這段是產生隨機的模型訓練資料及驗測資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_dim=f.shape[1]\n",
    "learning_rate=0.01\n",
    "training_epochs=1000\n",
    "display_step=50\n",
    "cost_history=np.empty(shape=[1],dtype=float)\n",
    "seed=2017\n",
    "\n",
    "# Constructing graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_dim])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set model weights\n",
    "w = tf.Variable(tf.random_normal([n_dim, 1], seed=seed), name=\"weight\")\n",
    "\n",
    "# Define cost function\n",
    "y_ = tf.matmul(x, w)\n",
    "cost = tf.reduce_mean(tf.square(y_ - y))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 這段是建立一個模型y_，他跟真實模型會有一個誤差，目的是把誤差減到最小，即y_-y的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Session & Initialization\n",
    "sess=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,\n",
    "    feed_dict={x:x_train,y:y_train})\n",
    "    cost_history=np.append(cost_history,\n",
    "                          sess.run(cost,feed_dict={x:x_train,y:y_train}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 下午實作部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# data\n",
    "mnist=input_data.read_data_sets(\"MNIST/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model parameters\n",
    "learning_rate=0.01\n",
    "epochs = 20\n",
    "batch_size=100\n",
    "nb_batch=int(mnist.train.num_examples/batch_size)\n",
    "display_step=1\n",
    "cost_history=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([10]))\n",
    "y=tf.add(tf.matmul(x,W),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 Cost=1.183907932\n",
      "Epoch:0002 Cost=0.665371387\n",
      "Epoch:0003 Cost=0.552838534\n",
      "Epoch:0004 Cost=0.498707824\n",
      "Epoch:0005 Cost=0.465535456\n",
      "Epoch:0006 Cost=0.442627445\n",
      "Epoch:0007 Cost=0.425560299\n",
      "Epoch:0008 Cost=0.412233437\n",
      "Epoch:0009 Cost=0.401436647\n",
      "Epoch:0010 Cost=0.392377033\n",
      "Epoch:0011 Cost=0.384775886\n",
      "Epoch:0012 Cost=0.378189199\n",
      "Epoch:0013 Cost=0.372416119\n",
      "Epoch:0014 Cost=0.367337827\n",
      "Epoch:0015 Cost=0.362717281\n",
      "Epoch:0016 Cost=0.358619152\n",
      "Epoch:0017 Cost=0.354898577\n",
      "Epoch:0018 Cost=0.351475001\n",
      "Epoch:0019 Cost=0.348347098\n",
      "Epoch:0020 Cost=0.345429354\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    avg_cost=0.\n",
    "    for _ in range(nb_batch):\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        _,c=sess.run([train_step,cost],\n",
    "                    feed_dict={x:batch_xs,y_:batch_ys})\n",
    "        avg_cost+=c/nb_batch\n",
    "        \n",
    "    cost_history.append(avg_cost)\n",
    "    if(epoch+1)%display_step==0:\n",
    "        print(\"Epoch:{:04d} Cost={:.9f}\".format(epoch+1,avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images,\n",
    "                                   y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "mnist = input_data.read_data_sets(\"MNIST/\", one_hot=True)\n",
    "                                  \n",
    "learning_rate = 0.01 \n",
    "epochs = 20\n",
    "batch_size = 100 \n",
    "nb_batch = int(mnist.train.num_examples/batch_size) \n",
    "display_step = 1\n",
    "cost_history = list() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 64 \n",
    "n_input_dim = 784 \n",
    "n_class = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store weights and bias definition \n",
    "weights = { \n",
    "    'h1': tf.Variable(tf.random_normal([n_input_dim, n_hidden_1])), \n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_class])) \n",
    "} \n",
    "bias = { \n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])), \n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'b3': tf.Variable(tf.random_normal([n_class])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, bias): \n",
    "    # Hidden Layer 1 - ReLu activation \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), bias['b1']) \n",
    "    layer_1 = tf.nn.relu(layer_1) \n",
    "    \n",
    "    # Hidden Layer 2 - ReLu activation \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), bias['b2']) \n",
    "    layer_2 = tf.nn.relu(layer_2) \n",
    "    \n",
    "    # Output Layer Linear activation \n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), bias['b3']) \n",
    "    return layer_3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constructing graph input (input feature normatized) \n",
    "x = tf.placeholder(tf.float32, [None, n_input_dim]) # MIST input 28x28 -> 784 \n",
    "y_ = tf.placeholder(tf.float32, [None, n_class]) # 10 digits -> 10 cLasses \n",
    "y = multilayer_perceptron(x, weights, bias) \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, \n",
    "                                                              logits=y)) \n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creo - \n",
    "sess = tf.InteractiveSession() \n",
    "# Initialize the variabtef \n",
    "tf.global_variables_initializer().run() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 Cost=22.025981406\n",
      "Epoch:0002 Cost=2.054608068\n",
      "Epoch:0003 Cost=1.597285672\n",
      "Epoch:0004 Cost=1.407760536\n",
      "Epoch:0005 Cost=1.305904414\n",
      "Epoch:0006 Cost=1.236106888\n",
      "Epoch:0007 Cost=1.173384563\n",
      "Epoch:0008 Cost=1.129876092\n",
      "Epoch:0009 Cost=1.091303134\n",
      "Epoch:0010 Cost=1.044371406\n",
      "Epoch:0011 Cost=1.012794874\n",
      "Epoch:0012 Cost=0.977672402\n",
      "Epoch:0013 Cost=0.947622979\n",
      "Epoch:0014 Cost=0.933352177\n",
      "Epoch:0015 Cost=0.897951126\n",
      "Epoch:0016 Cost=0.880312209\n",
      "Epoch:0017 Cost=0.858760628\n",
      "Epoch:0018 Cost=0.835389947\n",
      "Epoch:0019 Cost=0.819633080\n",
      "Epoch:0020 Cost=0.793951937\n",
      "Finished Optimization!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    avg_cost=0.\n",
    "    for _ in range(nb_batch):\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        _,c=sess.run([train_step,cost],\n",
    "                    feed_dict={x:batch_xs,y_:batch_ys})\n",
    "        avg_cost+=c/nb_batch\n",
    "        \n",
    "    cost_history.append(avg_cost)\n",
    "    # display log\n",
    "    if(epoch+1)%display_step==0:\n",
    "        print(\"Epoch:{:04d} Cost={:.9f}\".format(epoch+1,avg_cost))\n",
    "        \n",
    "print('Finished Optimization!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7849\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images,\n",
    "                                   y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create modeL\n",
    "def nultilayer_perceptron(x, weights, bias):\n",
    "    # Hidden Layer 1 - ReLu activation\n",
    "    layer_1 = tf.add(tf.natnu1(x, weights['w1']), bias['b1'])\n",
    "    layer_1 = tf.nn.re1u(layer_1)\n",
    "    tf.summary.histogram(\"re1u1\", layer_1)\n",
    "    # Hidden Layer 2 - ReLu activation\n",
    "    layer_2 = tf.add(tf.natnu1(layer_1, weights['w2']), biasl['b2'])\n",
    "    layer_2 = tf.nn.re1u(layer_2)\n",
    "    tf.summary.histogram(\"re1u2\", layer_2)\n",
    "    # Output Layer - Linear activation\n",
    "    layer_3 = tf.add(tf.natnu1(layer_2, ueights['w3']), biasl['b3'])\n",
    "    return layer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Summary name Variable:0 is illegal; using Variable_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_1:0 is illegal; using Variable_1_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_2:0 is illegal; using Variable_2_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_3:0 is illegal; using Variable_3_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_4:0 is illegal; using Variable_4_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_5:0 is illegal; using Variable_5_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_6:0 is illegal; using Variable_6_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_7:0 is illegal; using Variable_7_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_8:0 is illegal; using Variable_8_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_9:0 is illegal; using Variable_9_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_10:0 is illegal; using Variable_10_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_11:0 is illegal; using Variable_11_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_12:0 is illegal; using Variable_12_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_13:0 is illegal; using Variable_13_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_14:0 is illegal; using Variable_14_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_15:0 is illegal; using Variable_15_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_16:0 is illegal; using Variable_16_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_17:0 is illegal; using Variable_17_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_18:0 is illegal; using Variable_18_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_19:0 is illegal; using Variable_19_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_20:0 is illegal; using Variable_20_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_21:0 is illegal; using Variable_21_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_22:0 is illegal; using Variable_22_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_23:0 is illegal; using Variable_23_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_24:0 is illegal; using Variable_24_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_25:0 is illegal; using Variable_25_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_26:0 is illegal; using Variable_26_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_27:0 is illegal; using Variable_27_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_28:0 is illegal; using Variable_28_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_29:0 is illegal; using Variable_29_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_30:0 is illegal; using Variable_30_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_31:0 is illegal; using Variable_31_0 instead.\n",
      "INFO:tensorflow:Summary name Variable_32:0 is illegal; using Variable_32_0 instead.\n",
      "INFO:tensorflow:Summary name Weights/w1:0 is illegal; using Weights/w1_0 instead.\n",
      "INFO:tensorflow:Summary name Weights/w2:0 is illegal; using Weights/w2_0 instead.\n",
      "INFO:tensorflow:Summary name Weights/w3:0 is illegal; using Weights/w3_0 instead.\n",
      "INFO:tensorflow:Summary name Bias/b1:0 is illegal; using Bias/b1_0 instead.\n",
      "INFO:tensorflow:Summary name Bias/b2:0 is illegal; using Bias/b2_0 instead.\n",
      "INFO:tensorflow:Summary name Bias/b3:0 is illegal; using Bias/b3_0 instead.\n",
      "INFO:tensorflow:Summary name Weights_1/w1:0 is illegal; using Weights_1/w1_0 instead.\n",
      "INFO:tensorflow:Summary name Weights_1/w2:0 is illegal; using Weights_1/w2_0 instead.\n",
      "INFO:tensorflow:Summary name Weights_1/w3:0 is illegal; using Weights_1/w3_0 instead.\n",
      "INFO:tensorflow:Summary name Bias_1/b1:0 is illegal; using Bias_1/b1_0 instead.\n",
      "INFO:tensorflow:Summary name Bias_1/b2:0 is illegal; using Bias_1/b2_0 instead.\n",
      "INFO:tensorflow:Summary name Bias_1/b3:0 is illegal; using Bias_1/b3_0 instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,784] has negative dimensions\n\t [[Node: Placeholder_24 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_24', defined at:\n  File \"/Users/chia/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/chia/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-88-2246149560c9>\", line 2, in <module>\n    x = tf.placeholder(tf.float32, [None, n_input_dim]) # MIST input 28x28 -> 784\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,784] has negative dimensions\n\t [[Node: Placeholder_24 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,784] has negative dimensions\n\t [[Node: Placeholder_24 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-cead066fec69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         _, c, summary = sess.run([apply_grads, loss, merged_summary],\n\u001b[0;32m--> 121\u001b[0;31m                         feed_dict={x: batch_xs, y: batch_ys})\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Write logs at every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb_batch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,784] has negative dimensions\n\t [[Node: Placeholder_24 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_24', defined at:\n  File \"/Users/chia/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/chia/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-88-2246149560c9>\", line 2, in <module>\n    x = tf.placeholder(tf.float32, [None, n_input_dim]) # MIST input 28x28 -> 784\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,784] has negative dimensions\n\t [[Node: Placeholder_24 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST/\", one_hot=True)\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "nb_batch = int(mnist.train.num_examples/batch_size)\n",
    "display_step = 1\n",
    "logs_path = './logs/'\n",
    "\n",
    "\n",
    "# Network parameters\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 64\n",
    "n_input_dim = 784\n",
    "n_class = 10\n",
    "\n",
    "\n",
    "# Constructing graph input (input feature normalized)\n",
    "x = tf.placeholder(tf.float32, [None, n_input_dim])  # MNIST input 28x28 -> 784\n",
    "y = tf.placeholder(tf.float32, [None, n_class])  # 10 digits -> 10 classes\n",
    "\n",
    "# Xavier uniform initializer\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, bias):\n",
    "    # Hidden layer 1 - Relu activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), bias['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    tf.summary.histogram(\"relu1\", layer_1)\n",
    "\n",
    "    # Hidden layer 2 - Relu activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), bias['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    tf.summary.histogram(\"relu2\", layer_2)\n",
    "\n",
    "    # Output layer - Linear activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), bias['b3'])\n",
    "    return layer_3\n",
    "\n",
    "\n",
    "# tf tensorboard summary page\n",
    "with tf.name_scope('Weights'):\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input_dim, n_hidden_1]),\n",
    "                          name='w1'),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),\n",
    "                          name='w2'),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden_2, n_class]),\n",
    "                          name='w3')\n",
    "    }\n",
    "\n",
    "\n",
    "with tf.name_scope('Bias'):\n",
    "    bias = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1]),\n",
    "                          name='b1'),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2]),\n",
    "                          name='b2'),\n",
    "        'b3': tf.Variable(tf.random_normal([n_class]),\n",
    "                          name='b3')\n",
    "    }\n",
    "\n",
    "with tf.name_scope('Model'):\n",
    "    # Build model\n",
    "    pred = multilayer_perceptron(x, weights, bias)\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    # Softmax Cross entropy (cost function)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,\n",
    "                                                                  labels=y))\n",
    "\n",
    "with tf.name_scope('SGD'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    grads = tf.gradients(loss, tf.trainable_variables())\n",
    "    grads = list(zip(grads, tf.trainable_variables()))\n",
    "    apply_grads = optimizer.apply_gradients(grads_and_vars=grads)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# Create summaries to visualize weights\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "# Create session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Initialize the variables\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "summary_writer = tf.summary.FileWriter(logs_path,\n",
    "                                       graph=tf.get_default_graph())\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0.\n",
    "    for i in range(nb_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c, summary = sess.run([apply_grads, loss, merged_summary],\n",
    "                        feed_dict={x: batch_xs, y: batch_ys})\n",
    "        # Write logs at every iteration\n",
    "        summary_writer.add_summary(summary, epoch * nb_batch + i)\n",
    "        avg_cost += c/nb_batch\n",
    "    # display log\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Epoch: {:04d}   Cost= {:.9f}\".format(epoch+1, avg_cost))\n",
    "\n",
    "print ('Finished Optimization!')\n",
    "\n",
    "# Test model\n",
    "# Calculate accuracy\n",
    "print (\"Accuracy:\", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "print (\"Run the command line:\\n\" \\\n",
    "       \"--> tensorboard --logdir=./logs/\\n\" \\\n",
    "       \"Then open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir='/Users/chia/logs'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
