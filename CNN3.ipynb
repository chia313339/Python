{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.86666667,  0.85490196,  0.82745098],\n",
       "         [ 0.86666667,  0.85490196,  0.82745098],\n",
       "         [ 0.88235294,  0.86666667,  0.84313725],\n",
       "         ..., \n",
       "         [ 0.81176471,  0.81176471,  0.80392157],\n",
       "         [ 0.82745098,  0.82745098,  0.81960784],\n",
       "         [ 0.82745098,  0.82745098,  0.81960784]],\n",
       "\n",
       "        [[ 0.8745098 ,  0.8627451 ,  0.83529412],\n",
       "         [ 0.86666667,  0.85490196,  0.82745098],\n",
       "         [ 0.87843137,  0.8627451 ,  0.83921569],\n",
       "         ..., \n",
       "         [ 0.82352941,  0.82352941,  0.81568627],\n",
       "         [ 0.82745098,  0.82745098,  0.81960784],\n",
       "         [ 0.83137255,  0.83137255,  0.82352941]],\n",
       "\n",
       "        [[ 0.87843137,  0.86666667,  0.83921569],\n",
       "         [ 0.8745098 ,  0.8627451 ,  0.83529412],\n",
       "         [ 0.87843137,  0.8627451 ,  0.83921569],\n",
       "         ..., \n",
       "         [ 0.82352941,  0.82352941,  0.81568627],\n",
       "         [ 0.83137255,  0.83137255,  0.82352941],\n",
       "         [ 0.83921569,  0.83921569,  0.83137255]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.85098039,  0.84705882,  0.83137255],\n",
       "         [ 0.84705882,  0.84313725,  0.82745098],\n",
       "         [ 0.86666667,  0.8627451 ,  0.84313725],\n",
       "         ..., \n",
       "         [ 0.78431373,  0.78823529,  0.77254902],\n",
       "         [ 0.78823529,  0.79215686,  0.77647059],\n",
       "         [ 0.78039216,  0.78431373,  0.76470588]],\n",
       "\n",
       "        [[ 0.87058824,  0.8627451 ,  0.84705882],\n",
       "         [ 0.84313725,  0.84313725,  0.82745098],\n",
       "         [ 0.85882353,  0.85490196,  0.83921569],\n",
       "         ..., \n",
       "         [ 0.79215686,  0.79215686,  0.78431373],\n",
       "         [ 0.79607843,  0.8       ,  0.78039216],\n",
       "         [ 0.78431373,  0.78823529,  0.76862745]],\n",
       "\n",
       "        [[ 0.8745098 ,  0.86666667,  0.84705882],\n",
       "         [ 0.84313725,  0.84313725,  0.82745098],\n",
       "         [ 0.85490196,  0.85098039,  0.83921569],\n",
       "         ..., \n",
       "         [ 0.78823529,  0.78823529,  0.77647059],\n",
       "         [ 0.79607843,  0.8       ,  0.78039216],\n",
       "         [ 0.78431373,  0.78823529,  0.76862745]]],\n",
       "\n",
       "\n",
       "       [[[ 0.90196078,  0.86666667,  0.81568627],\n",
       "         [ 0.89803922,  0.8627451 ,  0.81176471],\n",
       "         [ 0.89411765,  0.85490196,  0.81568627],\n",
       "         ..., \n",
       "         [ 0.71764706,  0.69019608,  0.65882353],\n",
       "         [ 0.7254902 ,  0.69411765,  0.65098039],\n",
       "         [ 0.76862745,  0.7372549 ,  0.69411765]],\n",
       "\n",
       "        [[ 0.90196078,  0.86666667,  0.81960784],\n",
       "         [ 0.89411765,  0.85098039,  0.80392157],\n",
       "         [ 0.89019608,  0.85098039,  0.80784314],\n",
       "         ..., \n",
       "         [ 0.69411765,  0.66666667,  0.63921569],\n",
       "         [ 0.70980392,  0.67843137,  0.64313725],\n",
       "         [ 0.74117647,  0.70980392,  0.66666667]],\n",
       "\n",
       "        [[ 0.91372549,  0.87843137,  0.83529412],\n",
       "         [ 0.90980392,  0.87843137,  0.83137255],\n",
       "         [ 0.91764706,  0.88235294,  0.84313725],\n",
       "         ..., \n",
       "         [ 0.67843137,  0.65490196,  0.63137255],\n",
       "         [ 0.69019608,  0.65882353,  0.62352941],\n",
       "         [ 0.7254902 ,  0.69411765,  0.65490196]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.6       ,  0.56862745,  0.5372549 ],\n",
       "         [ 0.61568627,  0.58039216,  0.54901961],\n",
       "         [ 0.61568627,  0.58039216,  0.54509804],\n",
       "         ..., \n",
       "         [ 0.57254902,  0.54509804,  0.49803922],\n",
       "         [ 0.50980392,  0.48235294,  0.43921569],\n",
       "         [ 0.46666667,  0.44313725,  0.39607843]],\n",
       "\n",
       "        [[ 0.61960784,  0.58039216,  0.54901961],\n",
       "         [ 0.63921569,  0.6       ,  0.56862745],\n",
       "         [ 0.63921569,  0.60392157,  0.56862745],\n",
       "         ..., \n",
       "         [ 0.57647059,  0.54509804,  0.50196078],\n",
       "         [ 0.51372549,  0.48235294,  0.43529412],\n",
       "         [ 0.47843137,  0.45098039,  0.40784314]],\n",
       "\n",
       "        [[ 0.63529412,  0.59607843,  0.56078431],\n",
       "         [ 0.63529412,  0.59607843,  0.55686275],\n",
       "         [ 0.62352941,  0.58039216,  0.54509804],\n",
       "         ..., \n",
       "         [ 0.59607843,  0.56470588,  0.52156863],\n",
       "         [ 0.5254902 ,  0.50196078,  0.45490196],\n",
       "         [ 0.49019608,  0.46666667,  0.42352941]]],\n",
       "\n",
       "\n",
       "       [[[ 0.62745098,  0.64313725,  0.30196078],\n",
       "         [ 0.61176471,  0.63137255,  0.29803922],\n",
       "         [ 0.60392157,  0.63137255,  0.29411765],\n",
       "         ..., \n",
       "         [ 0.63921569,  0.6745098 ,  0.34901961],\n",
       "         [ 0.65882353,  0.69411765,  0.36078431],\n",
       "         [ 0.68235294,  0.70980392,  0.37254902]],\n",
       "\n",
       "        [[ 0.61176471,  0.62745098,  0.29411765],\n",
       "         [ 0.61176471,  0.62745098,  0.29803922],\n",
       "         [ 0.60784314,  0.62745098,  0.29803922],\n",
       "         ..., \n",
       "         [ 0.64705882,  0.68235294,  0.35686275],\n",
       "         [ 0.65882353,  0.69803922,  0.36470588],\n",
       "         [ 0.67058824,  0.69803922,  0.36470588]],\n",
       "\n",
       "        [[ 0.58823529,  0.60784314,  0.28235294],\n",
       "         [ 0.58823529,  0.61176471,  0.28627451],\n",
       "         [ 0.59215686,  0.61568627,  0.28627451],\n",
       "         ..., \n",
       "         [ 0.63921569,  0.67843137,  0.35686275],\n",
       "         [ 0.64313725,  0.67843137,  0.35294118],\n",
       "         [ 0.64705882,  0.6745098 ,  0.34117647]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.56078431,  0.56862745,  0.23921569],\n",
       "         [ 0.56470588,  0.57254902,  0.24313725],\n",
       "         [ 0.56862745,  0.58039216,  0.24705882],\n",
       "         ..., \n",
       "         [ 0.58039216,  0.62745098,  0.29411765],\n",
       "         [ 0.58039216,  0.62745098,  0.29411765],\n",
       "         [ 0.58823529,  0.63137255,  0.29411765]],\n",
       "\n",
       "        [[ 0.56078431,  0.56862745,  0.23921569],\n",
       "         [ 0.56470588,  0.57254902,  0.24313725],\n",
       "         [ 0.56470588,  0.57254902,  0.24313725],\n",
       "         ..., \n",
       "         [ 0.58431373,  0.62352941,  0.29411765],\n",
       "         [ 0.58823529,  0.62745098,  0.29803922],\n",
       "         [ 0.58431373,  0.62352941,  0.28627451]],\n",
       "\n",
       "        [[ 0.58039216,  0.58039216,  0.24705882],\n",
       "         [ 0.57254902,  0.57647059,  0.25098039],\n",
       "         [ 0.56862745,  0.57647059,  0.24705882],\n",
       "         ..., \n",
       "         [ 0.58823529,  0.62352941,  0.29411765],\n",
       "         [ 0.58823529,  0.62745098,  0.29019608],\n",
       "         [ 0.58039216,  0.61960784,  0.27843137]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.24313725,  0.14901961,  0.13333333],\n",
       "         [ 0.11372549,  0.0745098 ,  0.09803922],\n",
       "         [ 0.09019608,  0.0627451 ,  0.09411765],\n",
       "         ..., \n",
       "         [ 0.58039216,  0.55294118,  0.58039216],\n",
       "         [ 0.58039216,  0.55294118,  0.57647059],\n",
       "         [ 0.57254902,  0.54901961,  0.55686275]],\n",
       "\n",
       "        [[ 0.14901961,  0.09019608,  0.10588235],\n",
       "         [ 0.10196078,  0.06666667,  0.09411765],\n",
       "         [ 0.10196078,  0.06666667,  0.09411765],\n",
       "         ..., \n",
       "         [ 0.74509804,  0.7254902 ,  0.71372549],\n",
       "         [ 0.74901961,  0.7254902 ,  0.71764706],\n",
       "         [ 0.75294118,  0.7254902 ,  0.73333333]],\n",
       "\n",
       "        [[ 0.17254902,  0.10196078,  0.10980392],\n",
       "         [ 0.21568627,  0.11764706,  0.12156863],\n",
       "         [ 0.24705882,  0.1372549 ,  0.1372549 ],\n",
       "         ..., \n",
       "         [ 0.81960784,  0.8       ,  0.78431373],\n",
       "         [ 0.83137255,  0.80392157,  0.79215686],\n",
       "         [ 0.84705882,  0.79607843,  0.79607843]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.38431373,  0.38431373,  0.38431373],\n",
       "         [ 0.39607843,  0.39607843,  0.39607843],\n",
       "         [ 0.40784314,  0.40784314,  0.40784314],\n",
       "         ..., \n",
       "         [ 0.79607843,  0.78039216,  0.7372549 ],\n",
       "         [ 0.83529412,  0.81960784,  0.77254902],\n",
       "         [ 0.88627451,  0.87058824,  0.82352941]],\n",
       "\n",
       "        [[ 0.39215686,  0.39215686,  0.39215686],\n",
       "         [ 0.40392157,  0.40392157,  0.40392157],\n",
       "         [ 0.41960784,  0.41960784,  0.41960784],\n",
       "         ..., \n",
       "         [ 0.81176471,  0.79607843,  0.74901961],\n",
       "         [ 0.81568627,  0.8       ,  0.75294118],\n",
       "         [ 0.82352941,  0.80784314,  0.76078431]],\n",
       "\n",
       "        [[ 0.39215686,  0.39215686,  0.39215686],\n",
       "         [ 0.40392157,  0.40392157,  0.40392157],\n",
       "         [ 0.41960784,  0.41960784,  0.41960784],\n",
       "         ..., \n",
       "         [ 0.85882353,  0.84313725,  0.79607843],\n",
       "         [ 0.87843137,  0.8627451 ,  0.81568627],\n",
       "         [ 0.89019608,  0.8745098 ,  0.82745098]]],\n",
       "\n",
       "\n",
       "       [[[ 0.5372549 ,  0.6627451 ,  0.65882353],\n",
       "         [ 0.62745098,  0.74509804,  0.75686275],\n",
       "         [ 0.65098039,  0.76078431,  0.77254902],\n",
       "         ..., \n",
       "         [ 0.6       ,  0.74117647,  0.74901961],\n",
       "         [ 0.57254902,  0.72941176,  0.7372549 ],\n",
       "         [ 0.58431373,  0.73333333,  0.7372549 ]],\n",
       "\n",
       "        [[ 0.4745098 ,  0.62352941,  0.61960784],\n",
       "         [ 0.56078431,  0.71764706,  0.71764706],\n",
       "         [ 0.59215686,  0.7372549 ,  0.74117647],\n",
       "         ..., \n",
       "         [ 0.66666667,  0.74901961,  0.77254902],\n",
       "         [ 0.65882353,  0.76862745,  0.78431373],\n",
       "         [ 0.6745098 ,  0.79607843,  0.8       ]],\n",
       "\n",
       "        [[ 0.61568627,  0.7254902 ,  0.72156863],\n",
       "         [ 0.70196078,  0.8       ,  0.80392157],\n",
       "         [ 0.7254902 ,  0.81568627,  0.82352941],\n",
       "         ..., \n",
       "         [ 0.77647059,  0.82352941,  0.85882353],\n",
       "         [ 0.78431373,  0.85882353,  0.8745098 ],\n",
       "         [ 0.79215686,  0.87843137,  0.88627451]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.80392157,  0.8745098 ,  0.8745098 ],\n",
       "         [ 0.8745098 ,  0.9254902 ,  0.94117647],\n",
       "         [ 0.89019608,  0.9254902 ,  0.94901961],\n",
       "         ..., \n",
       "         [ 0.88627451,  0.94117647,  0.94901961],\n",
       "         [ 0.8745098 ,  0.9372549 ,  0.94509804],\n",
       "         [ 0.87843137,  0.93333333,  0.94509804]],\n",
       "\n",
       "        [[ 0.7372549 ,  0.80784314,  0.8       ],\n",
       "         [ 0.87843137,  0.9372549 ,  0.94117647],\n",
       "         [ 0.88627451,  0.9372549 ,  0.94901961],\n",
       "         ..., \n",
       "         [ 0.80784314,  0.87843137,  0.87843137],\n",
       "         [ 0.78823529,  0.86666667,  0.8627451 ],\n",
       "         [ 0.74901961,  0.82352941,  0.81568627]],\n",
       "\n",
       "        [[ 0.54509804,  0.61568627,  0.59607843],\n",
       "         [ 0.66666667,  0.7372549 ,  0.71764706],\n",
       "         [ 0.68627451,  0.76470588,  0.75294118],\n",
       "         ..., \n",
       "         [ 0.55686275,  0.6745098 ,  0.65098039],\n",
       "         [ 0.54117647,  0.65490196,  0.62745098],\n",
       "         [ 0.5372549 ,  0.63137255,  0.60392157]]],\n",
       "\n",
       "\n",
       "       [[[ 0.73333333,  0.72941176,  0.74117647],\n",
       "         [ 0.74117647,  0.72941176,  0.74117647],\n",
       "         [ 0.7254902 ,  0.71372549,  0.72941176],\n",
       "         ..., \n",
       "         [ 0.74901961,  0.76862745,  0.74901961],\n",
       "         [ 0.7254902 ,  0.73333333,  0.72941176],\n",
       "         [ 0.71372549,  0.73333333,  0.73333333]],\n",
       "\n",
       "        [[ 0.74509804,  0.72941176,  0.72941176],\n",
       "         [ 0.74117647,  0.7254902 ,  0.7254902 ],\n",
       "         [ 0.72156863,  0.71372549,  0.71372549],\n",
       "         ..., \n",
       "         [ 0.74901961,  0.76470588,  0.74117647],\n",
       "         [ 0.7254902 ,  0.73333333,  0.7254902 ],\n",
       "         [ 0.71372549,  0.73333333,  0.7254902 ]],\n",
       "\n",
       "        [[ 0.74901961,  0.72941176,  0.7254902 ],\n",
       "         [ 0.74117647,  0.72156863,  0.72156863],\n",
       "         [ 0.70980392,  0.71372549,  0.70980392],\n",
       "         ..., \n",
       "         [ 0.74117647,  0.75294118,  0.73333333],\n",
       "         [ 0.72156863,  0.72941176,  0.71764706],\n",
       "         [ 0.70196078,  0.7254902 ,  0.70980392]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.48627451,  0.42352941,  0.4       ],\n",
       "         [ 0.19215686,  0.17254902,  0.16078431],\n",
       "         [ 0.11764706,  0.10588235,  0.10196078],\n",
       "         ..., \n",
       "         [ 0.71372549,  0.7254902 ,  0.70588235],\n",
       "         [ 0.7254902 ,  0.74509804,  0.73333333],\n",
       "         [ 0.70980392,  0.7254902 ,  0.71764706]],\n",
       "\n",
       "        [[ 0.49803922,  0.43921569,  0.41568627],\n",
       "         [ 0.28235294,  0.25098039,  0.23137255],\n",
       "         [ 0.26666667,  0.22745098,  0.22352941],\n",
       "         ..., \n",
       "         [ 0.7254902 ,  0.7372549 ,  0.72156863],\n",
       "         [ 0.73333333,  0.74901961,  0.7372549 ],\n",
       "         [ 0.69803922,  0.72156863,  0.71764706]],\n",
       "\n",
       "        [[ 0.55294118,  0.47843137,  0.45490196],\n",
       "         [ 0.53333333,  0.46666667,  0.45098039],\n",
       "         [ 0.52156863,  0.4627451 ,  0.45098039],\n",
       "         ..., \n",
       "         [ 0.73333333,  0.74117647,  0.72941176],\n",
       "         [ 0.72941176,  0.73333333,  0.7254902 ],\n",
       "         [ 0.68627451,  0.71372549,  0.71764706]]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "image_list_array = []\n",
    "label_d = []\n",
    "img_temp=[]\n",
    "for filename in glob.glob('/Users/chia/Downloads/HPEImages/*.jpg'): #assuming gif\n",
    "    name = filename[filename.rfind('/')+1:filename.rfind('.')-1]\n",
    "#     print(name)\n",
    "    label_d.append(name)\n",
    "    im=misc.imresize(Image.open(filename), (50,50))\n",
    "    image_list.append(im)\n",
    "    image_list_array.append(np.array(im))\n",
    "    \n",
    "img = np.array(image_list_array)/255.\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=[]\n",
    "label.append(0)\n",
    "num=0\n",
    "for i in range(len(label_d)-1):\n",
    "    if label_d[i] == label_d[i+1]:\n",
    "        label.append(num)\n",
    "    else :\n",
    "        num=num+1\n",
    "        label.append(num)\n",
    "        \n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)\n",
    "enc = np.zeros([len(label), num])\n",
    "# np.array([list(range(0, 100))]\n",
    "list(range(0, 100))\n",
    "\n",
    "def one(x,max_x):\n",
    "    encode=np.zeros([len(x),max_x])\n",
    "    encode[[i for i in range (len(x))],x]=1\n",
    "    return encode\n",
    "\n",
    "ylabel = one(label,max(label)+1)\n",
    "ylabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/chia/Downloads/HPEImages/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/chia/Downloads/HPEImages/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/chia/Downloads/HPEImages/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/chia/Downloads/HPEImages/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Download Done!\n",
      "WARNING:tensorflow:From /Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (41, 50, 50, 3) for Tensor 'Placeholder_27:0', which has shape '(?, 2500)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-32f90a6ae28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtrain_accuacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3926\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3927\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3928\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (41, 50, 50, 3) for Tensor 'Placeholder_27:0', which has shape '(?, 2500)'"
     ]
    }
   ],
   "source": [
    "__author__ = 'chapter'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def weight_varible(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/Users/chia/Downloads/HPEImages/MNIST\", one_hot=True)\n",
    "print(\"Download Done!\")\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# paras\n",
    "W_conv1 = weight_varible([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# conv layer-1\n",
    "x = tf.placeholder(tf.float32, [None, 2500])\n",
    "x_image = tf.reshape(x, [-1, 50, 50, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# conv layer-2\n",
    "W_conv2 = weight_varible([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# full connection\n",
    "W_fc1 = weight_varible([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# output layer: softmax\n",
    "W_fc2 = weight_varible([1024, 8])\n",
    "b_fc2 = bias_variable([8])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "y_ = tf.placeholder(tf.float32, [None, 8])\n",
    "\n",
    "# model training\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.arg_max(y_conv, 1), tf.arg_max(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        train_accuacy = accuracy.eval(feed_dict={x: img, y_: ylabel, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuacy))\n",
    "    train_step.run(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "# accuacy on test\n",
    "print(\"test accuracy %g\"%(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-92a0979b257f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-92a0979b257f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# Actually run with the new settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mmnist_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_two_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_two_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-92a0979b257f>\u001b[0m in \u001b[0;36mmnist_model\u001b[0;34m(learning_rate, use_two_conv, use_two_fc, hparam)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOGDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_hparam_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_two_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_two_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chia/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright 2017 Google, Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "  from urllib.request import urlretrieve\n",
    "else:\n",
    "  from urllib import urlretrieve\n",
    "\n",
    "LOGDIR = '/tmp/mnist_tutorial/'\n",
    "GITHUB_URL ='https://raw.githubusercontent.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/master/'\n",
    "\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "urlretrieve(GITHUB_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "urlretrieve(GITHUB_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')\n",
    "\n",
    "# Add convolution layer\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Add fully connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.Session()\n",
    "\n",
    "  # Setup placeholders, and reshape the data\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.summary.image('input', x_image, 3)\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "  if use_two_conv:\n",
    "    conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "  else:\n",
    "    conv1 = conv_layer(x_image, 1, 64, \"conv\")\n",
    "    conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "  flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "  if use_two_fc:\n",
    "    fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "    embedding_input = fc1\n",
    "    embedding_size = 1024\n",
    "    logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "  else:\n",
    "    embedding_input = flattened\n",
    "    embedding_size = 7*7*64\n",
    "    logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "  with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=y), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "  with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "  with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "  summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "  embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "  assignment = embedding.assign(embedding_input)\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "  writer.add_graph(sess.graph)\n",
    "\n",
    "  config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "  embedding_config = config.embeddings.add()\n",
    "  embedding_config.tensor_name = embedding.name\n",
    "  embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "  embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "  # Specify the width and height of a single thumbnail.\n",
    "  embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "  tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "  for i in range(2001):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "      [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "      writer.add_summary(s, i)\n",
    "    if i % 500 == 0:\n",
    "      sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "      saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "  conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "  fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "  return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "def main():\n",
    "  # You can try adding some more learning rates\n",
    "  for learning_rate in [1E-4]:\n",
    "\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    for use_two_fc in [True]:\n",
    "      for use_two_conv in [True]:\n",
    "        # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "        hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "        print('Starting run for %s' % hparam)\n",
    "\n",
    "\t    # Actually run with the new settings\n",
    "        mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1280, Minibatch Loss= 17405.632812, Training Accuracy= 0.25781\n",
      "Iter 2560, Minibatch Loss= 22148.980469, Training Accuracy= 0.32031\n",
      "Iter 3840, Minibatch Loss= 9720.496094, Training Accuracy= 0.49219\n",
      "Iter 5120, Minibatch Loss= 5302.509766, Training Accuracy= 0.63281\n",
      "Iter 6400, Minibatch Loss= 5502.010742, Training Accuracy= 0.71094\n",
      "Iter 7680, Minibatch Loss= 4671.394531, Training Accuracy= 0.71094\n",
      "Iter 8960, Minibatch Loss= 5127.415527, Training Accuracy= 0.67969\n",
      "Iter 10240, Minibatch Loss= 5013.682617, Training Accuracy= 0.67188\n",
      "Iter 11520, Minibatch Loss= 3087.378906, Training Accuracy= 0.80469\n",
      "Iter 12800, Minibatch Loss= 3436.803223, Training Accuracy= 0.73438\n",
      "Iter 14080, Minibatch Loss= 2182.807861, Training Accuracy= 0.83594\n",
      "Iter 15360, Minibatch Loss= 3993.910156, Training Accuracy= 0.79688\n",
      "Iter 16640, Minibatch Loss= 2591.775879, Training Accuracy= 0.75000\n",
      "Iter 17920, Minibatch Loss= 2619.547852, Training Accuracy= 0.80469\n",
      "Iter 19200, Minibatch Loss= 2302.745605, Training Accuracy= 0.84375\n",
      "Iter 20480, Minibatch Loss= 2055.310547, Training Accuracy= 0.85156\n",
      "Iter 21760, Minibatch Loss= 2714.115723, Training Accuracy= 0.83594\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "# import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import tensorflow as tf\n",
    " \n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 400000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    " \n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    " \n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    " \n",
    "# Create model\n",
    "def conv2d(img, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add\\\n",
    "                      (tf.nn.conv2d(img, w,\\\n",
    "                                    strides=[1, 1, 1, 1],\\\n",
    "                                    padding='SAME'),b))\n",
    " \n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img, \\\n",
    "                          ksize=[1, k, k, 1],\\\n",
    "                          strides=[1, k, k, 1],\\\n",
    "                          padding='SAME')\n",
    " \n",
    "# Store layers weight & bias\n",
    " \n",
    "wc1 = tf.Variable(tf.random_normal([5, 5, 1, 32])) # 5x5 conv, 1 input, 32 outputs\n",
    "wc2 = tf.Variable(tf.random_normal([5, 5, 32, 64])) # 5x5 conv, 32 inputs, 64 outputs\n",
    "wd1 = tf.Variable(tf.random_normal([7*7*64, 1024])) # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "wout = tf.Variable(tf.random_normal([1024, n_classes])) # 1024 inputs, 10 outputs (class prediction)\n",
    " \n",
    "bc1 = tf.Variable(tf.random_normal([32]))\n",
    "bc2 = tf.Variable(tf.random_normal([64]))\n",
    "bd1 = tf.Variable(tf.random_normal([1024]))\n",
    "bout = tf.Variable(tf.random_normal([n_classes]))\n",
    " \n",
    "# Construct model\n",
    "_X = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    " \n",
    "# Convolution Layer\n",
    "conv1 = conv2d(_X,wc1,bc1)\n",
    "# Max Pooling (down-sampling)\n",
    "conv1 = max_pool(conv1, k=2)\n",
    "# Apply Dropout\n",
    "conv1 = tf.nn.dropout(conv1,keep_prob)\n",
    " \n",
    "# Convolution Layer\n",
    "conv2 = conv2d(conv1,wc2,bc2)\n",
    "# Max Pooling (down-sampling)\n",
    "conv2 = max_pool(conv2, k=2)\n",
    "# Apply Dropout\n",
    "conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    " \n",
    "# Fully connected layer\n",
    "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]]) # Reshape conv2 output to fit dense layer input\n",
    "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1),bd1)) # Relu activation\n",
    "dense1 = tf.nn.dropout(dense1, keep_prob) # Apply Dropout\n",
    " \n",
    "# Output, class prediction\n",
    "pred = tf.add(tf.matmul(dense1, wout), bout)\n",
    " \n",
    "#pred = conv_net(x, weights, biases, keep_prob)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    " \n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    " \n",
    "# Initializing the variables\n",
    "#init = tf.initialize_all_variables()\n",
    "init =tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            print (\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print (\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024], keep_prob: 1.}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
